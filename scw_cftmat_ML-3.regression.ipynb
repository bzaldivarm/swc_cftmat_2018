{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "import numpy as np\n",
    "import scipy.integrate as integrate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICAL INFERENCE 1: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the process of deducing properties of an underlying distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Least squares "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: generate data from function y(x)=(x-5)^2 + 10, adding Gaussian noise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If underlying PDF of data $y$ is i.i.d. as Gaussian, likelihood is: \n",
    "$$\n",
    "{\\cal L}(\\bf w) = \\prod_{i=1}^N  {\\cal N}(y_i|\\bar{y}_i,\\sigma_y)\n",
    "$$\n",
    "\n",
    "where \n",
    "$$  \\bar y_i = \\bar y_i({\\bf w}) $$\n",
    "\n",
    "and ${\\bf w}$ are the parameters of the machine-learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given model, choose the parameters that **maximise** the likelihood (MLE). For Gaussian, equivalent to minimise:\n",
    "$$\n",
    "{\\rm Cost} = \\frac{1}{N}\\sum_{i=1}^N \\big( y_i - \\bar{y}_i({\\bf w})\\big)^2~~~~~ (\\rm MSE)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: define Cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Machine Learning procedure:**  choose the model for $\\bar y(x)$ that best fit **new data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume a basis of functions like \n",
    "$$ f(x) = \\beta_0 + \\sum_{p=1}^P \\beta_p x^p = \\beta^T\\cdot \\vec\\phi(x)  $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then the result of minimisation can be computed analytically, and is:\n",
    "$$\n",
    "\\beta_{\\rm ML} = (\\Phi^T\\Phi)^{-1}\\Phi^T\\cdot {\\bf y}~~~~~~~~~~(1)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Phi(x,P):\n",
    "    # x: input vector\n",
    "    # P: order of polynomial\n",
    "    xt=x.reshape((-1,1))\n",
    "    Phi=np.ones(len(x)).reshape((-1,1))\n",
    "    for p in range(1,P+1):\n",
    "        Phi=np.hstack((Phi,xt**p))\n",
    "    return Phi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: define Beta function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea is to have optimal prediction in data never seen before:\n",
    "Dataset _randomly_ partitioned into **training** and **test** sets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: reshuffle and partition data in training and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def y_pred(Phi,beta):\n",
    "    # beta: vector of coefficients\n",
    "    # Phi:  Nx(P+1) matrix of features (inputs)\n",
    "    return Phi.dot(beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given model complexity $P$, the training fit is already given by expr.(1) \n",
    "evaluated in the training set  (in more complex models, numerical training is needed). The solution for $P=3$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: plot results for order 6 polynomial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**:Let's evaluate the Cost in the training and in the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
